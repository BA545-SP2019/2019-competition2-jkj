{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# **Cross-Validation & Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X12_ABS</th>\n",
       "      <th>X13_ABS</th>\n",
       "      <th>X14_ABS</th>\n",
       "      <th>X15_ABS</th>\n",
       "      <th>X16_ABS</th>\n",
       "      <th>X17_ABS</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>...</th>\n",
       "      <th>X15_M</th>\n",
       "      <th>X16_M</th>\n",
       "      <th>X17_M</th>\n",
       "      <th>X18_BI</th>\n",
       "      <th>X19_BI</th>\n",
       "      <th>X20_BI</th>\n",
       "      <th>X21_BI</th>\n",
       "      <th>X22_BI</th>\n",
       "      <th>X23_BI</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.869598</td>\n",
       "      <td>-0.758386</td>\n",
       "      <td>-0.785153</td>\n",
       "      <td>-1.088616</td>\n",
       "      <td>-1.579920</td>\n",
       "      <td>-1.541281</td>\n",
       "      <td>-1.483532</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034263</td>\n",
       "      <td>-0.866772</td>\n",
       "      <td>-0.935035</td>\n",
       "      <td>-0.794573</td>\n",
       "      <td>-0.699341</td>\n",
       "      <td>-0.636680</td>\n",
       "      <td>-0.606347</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.271418</td>\n",
       "      <td>0.116536</td>\n",
       "      <td>-0.233725</td>\n",
       "      <td>-0.216424</td>\n",
       "      <td>-0.139167</td>\n",
       "      <td>-0.067265</td>\n",
       "      <td>-0.007117</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.895980</td>\n",
       "      <td>0.423406</td>\n",
       "      <td>0.476861</td>\n",
       "      <td>0.528327</td>\n",
       "      <td>0.227939</td>\n",
       "      <td>0.296254</td>\n",
       "      <td>0.345181</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.895980</td>\n",
       "      <td>-0.482617</td>\n",
       "      <td>-0.597292</td>\n",
       "      <td>0.313576</td>\n",
       "      <td>0.054974</td>\n",
       "      <td>0.059507</td>\n",
       "      <td>0.098518</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1   X12_ABS   X13_ABS   X14_ABS   X15_ABS   X16_ABS   X17_ABS  X2  \\\n",
       "0 -1.869598 -0.758386 -0.785153 -1.088616 -1.579920 -1.541281 -1.483532   2   \n",
       "1  0.034263 -0.866772 -0.935035 -0.794573 -0.699341 -0.636680 -0.606347   2   \n",
       "2 -0.271418  0.116536 -0.233725 -0.216424 -0.139167 -0.067265 -0.007117   2   \n",
       "3 -0.895980  0.423406  0.476861  0.528327  0.227939  0.296254  0.345181   2   \n",
       "4 -0.895980 -0.482617 -0.597292  0.313576  0.054974  0.059507  0.098518   1   \n",
       "\n",
       "   X3  X4 ...  X15_M  X16_M  X17_M  X18_BI  X19_BI  X20_BI  X21_BI  X22_BI  \\\n",
       "0   2   1 ...      3      2      1       0       1       0       0       0   \n",
       "1   2   2 ...      3      2      1       0       1       1       1       0   \n",
       "2   2   2 ...      3      2      1       1       1       1       1       1   \n",
       "3   2   1 ...      3      2      1       1       1       1       1       1   \n",
       "4   2   1 ...      3      2      1       1       1       1       1       1   \n",
       "\n",
       "   X23_BI  Y  \n",
       "0       0  1  \n",
       "1       1  1  \n",
       "2       1  0  \n",
       "3       1  0  \n",
       "4       1  0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Excel file, calling the DataFrame comp_df\n",
    "df = pd.read_csv('Final5', header=0, index_col=0)\n",
    "# Checking import \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1] # Features\n",
    "y = df.Y # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Balancing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=2019)\n",
    "X_resample, y_resample = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jhoffmann/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jupyter-jhoffmann/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jupyter-jhoffmann/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jupyter-jhoffmann/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jupyter-jhoffmann/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jupyter-jhoffmann/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jupyter-jhoffmann/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:LogisticRegression, Score: mean=0.80790, var=0.00001\n",
      "Model:KNeighborsClassifier, Score: mean=0.78947, var=0.00002\n",
      "Model:DecisionTreeClassifier, Score: mean=0.80453, var=0.00002\n"
     ]
    }
   ],
   "source": [
    "# cross_valid_ex.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create object of class 'load_iris'\n",
    "#df = load_df()\n",
    "\n",
    "# save features and targets from the 'iris'\n",
    "features, targets = X, y\n",
    "\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression(C=5.0, dual=False, penalty=\"l2\")))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "#models.append(('SVC', SVC()))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=9,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=16, min_samples_split=6,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')))\n",
    "\n",
    "# KFold with 'stratify' option\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=23)\n",
    "for name, model in models:\n",
    "    score = cross_val_score(model, features, targets, cv=cv)\n",
    "    print(\"Model:{0}, Score: mean={1:0.5f}, var={2:0.5f}\".format(\n",
    "        name,\n",
    "        score.mean(),\n",
    "        score.var()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AdaBoostClassifier with Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7053586714603663\n",
      "0.7661691138722629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73     23364\n",
      "           1       0.75      0.62      0.68     23364\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     46728\n",
      "   macro avg       0.71      0.71      0.70     46728\n",
      "weighted avg       0.71      0.71      0.70     46728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "seed = 2019\n",
    "num_trees = 70\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "predicted = model_selection.cross_val_predict(model, X_resample, y_resample, cv=10)\n",
    "\n",
    "print(metrics.accuracy_score(y_resample, predicted))\n",
    "print(cross_val_score(model, X_resample, y_resample, cv=10, scoring='roc_auc').mean())\n",
    "print(metrics.classification_report(y_resample, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree with Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8904083204930663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88     23364\n",
      "           1       0.83      0.98      0.90     23364\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     46728\n",
      "   macro avg       0.90      0.89      0.89     46728\n",
      "weighted avg       0.90      0.89      0.89     46728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Decision Tree Classifier  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create Decision Tree Classifier Object \n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_resample, y_resample)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "predicted = model_selection.cross_val_predict(clf, X_resample, y_resample, cv=kfold)\n",
    "\n",
    "print(metrics.accuracy_score(y_resample, predicted))\n",
    "#print(cross_val_score(clf, X_resample, y_resample, cv=10, scoring='roc_auc').mean())\n",
    "print(metrics.classification_report(y_resample, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X6_BI      0.159143\n",
       "X12_ABS    0.116703\n",
       "X15_ABS    0.099188\n",
       "X13_ABS    0.097796\n",
       "X17_ABS    0.095787\n",
       "X14_ABS    0.092715\n",
       "X16_ABS    0.080286\n",
       "X1         0.078959\n",
       "X3         0.027105\n",
       "X5_Bins    0.024623\n",
       "X8_BI      0.015584\n",
       "X4         0.014716\n",
       "X12_BI     0.014215\n",
       "X2         0.014133\n",
       "X11_BI     0.008670\n",
       "X20_BI     0.008334\n",
       "X23_BI     0.007905\n",
       "X9_BI      0.006771\n",
       "X10_BI     0.005545\n",
       "X22_BI     0.005502\n",
       "X7_BI      0.005285\n",
       "X21_BI     0.004114\n",
       "X19_BI     0.003937\n",
       "X18_BI     0.003855\n",
       "X17_BI     0.002623\n",
       "X16_BI     0.002242\n",
       "X14_BI     0.001727\n",
       "X13_BI     0.001426\n",
       "X15_BI     0.001111\n",
       "X15_M      0.000000\n",
       "X14_M      0.000000\n",
       "X16_M      0.000000\n",
       "X17_M      0.000000\n",
       "X12_M      0.000000\n",
       "X13_M      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.Series(clf.feature_importances_, index=df.iloc[:,:-1].columns).sort_values(ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Using Feauture Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfeat10 = df.filter(['X6_BI', 'X13_ABS', 'X12_ABS', 'X14_ABS', 'X15_ABS', 'X16_ABS', 'X17_ABS', 'X1']) # Features\n",
    "y = df.Y # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=2019)\n",
    "X_resample_feat10, y_resample = ros.fit_resample(Xfeat10, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8826399589111453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87     23364\n",
      "           1       0.82      0.98      0.89     23364\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     46728\n",
      "   macro avg       0.90      0.88      0.88     46728\n",
      "weighted avg       0.90      0.88      0.88     46728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Decision Tree Classifier  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create Decision Tree Classifier Object \n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_resample_feat10, y_resample)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "predicted = model_selection.cross_val_predict(clf, X_resample_feat10, y_resample, cv=kfold)\n",
    "\n",
    "print(metrics.accuracy_score(y_resample, predicted))\n",
    "#print(cross_val_score(clf, X_resample, y_resample, cv=10, scoring='roc_auc').mean())\n",
    "print(metrics.classification_report(y_resample, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Decision Tree using TPOT Suggestion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6804057524396507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.73      0.69     23364\n",
      "           1       0.70      0.63      0.66     23364\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     46728\n",
      "   macro avg       0.68      0.68      0.68     46728\n",
      "weighted avg       0.68      0.68      0.68     46728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Decision Tree Classifier  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create Decision Tree Classifier Object \n",
    "clf = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=9,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=16, min_samples_split=6,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "clf = clf.fit(X_resample, y_resample)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "predicted = model_selection.cross_val_predict(clf, X_resample_feat10, y_resample, cv=kfold)\n",
    "\n",
    "print(metrics.accuracy_score(y_resample, predicted))\n",
    "#print(cross_val_score(clf, X_resample, y_resample, cv=10, scoring='roc_auc').mean())\n",
    "print(metrics.classification_report(y_resample, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression with Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6802559493237459\n",
      "0.7449374834029472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.71     23364\n",
      "           1       0.73      0.57      0.64     23364\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     46728\n",
      "   macro avg       0.69      0.68      0.68     46728\n",
      "weighted avg       0.69      0.68      0.68     46728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg = logreg.fit(X_resample,y_resample)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "predicted = model_selection.cross_val_predict(logreg, X_resample, y_resample, cv=kfold)\n",
    "print(metrics.accuracy_score(y_resample, predicted))\n",
    "print(cross_val_score(logreg, X_resample, y_resample, cv=10, scoring='roc_auc').mean())\n",
    "print(metrics.classification_report(y_resample, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SVC with Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='rbf', gamma='auto')  #Kernel=rbf, non-linearly separable data\n",
    "svclassifier = svclassifier.fit(X_resample, y_resample)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "results = model_selection.cross_val_score(svclassifier, X_resample, y_resample, cv=kfold)\n",
    "print(results)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
